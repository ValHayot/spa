\documentclass{IEEEtran}
\usepackage[hyphens]{url}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{colortbl} % for \rowcolor
\usepackage{caption}
\usepackage{subcaption}
\usepackage[bookmarks=false]{hyperref}
\usepackage{hyperref}
\hypersetup{colorlinks=true,linkcolor=black,citecolor=blue,filecolor=black,urlcolor=blue}

\newcommand{\tristan}[1]{\color{red}\textbf{Note from Tristan}:
      #1 \color{black}}

\newcommand{\todo}[1]{\marginpar{\parbox{18mm}{\flushleft\tiny\color{red}\textbf{TODO}:
      #1}}}
\definecolor{headcolor}{gray}{0.9}

\begin{document}
\title{SPA: An Apache Spark Pilot scheduler for HPC applications}
\author{
    \IEEEauthorblockN{
        Val\'erie Hayot-Sasson and Tristan Glatard
    }
    \IEEEauthorblockA{}
}
\maketitle

\begin{abstract}
    Big Data processing engines such as Apache Spark are increasingly 
    used to process scientific data. These processing engines, however, 
    have been primarily designed to work on dedicated infrastructure 
    and are not well designed to work on High-Performance Computing 
    (HPC) systems commonly available to researchers. Typical mechanisms 
    for launching Spark-based applications on HPC clusters involve 
    batch-requesting of the resources which can greatly increase 
    queueing times of the Big Data 
    applications. Pilot-scheduling is a well known HPC scheduling
    strategy that begins scheduling as compute resources are allocated to the 
    user, thereby reducing HPC scheduling wait times. Here, we introduce SPA, an
    open-source
    pilot-job submission system designed for launching Apache Spark pipelines 
    on Slurm-based clusters. SPA leverages optimizations available in Spark, 
    such as robust workers, masters and driver, in addition to 
    checkpointing, to ensure that processing occurs even when nodes are 
    lost due to expired walltime. SPA also ensures that a 
    user-specified number of pilots is maintained in the cluster in 
    order to ensure a constant level of parallelism. Should pilots be 
    idle for a certain amount of time, they are terminated by 
    the system. \tristan{Add a sentence on results when you have them.}

\end{abstract}

\section{Introduction}
\section{Materials and Methods}\label{sec:methods}
    \todo{walltime parameter of workflow}
    \subsection{Added value of pilot scheduling}
        \todo{execution of a batch cluster vs dynamic (pilot) cluster}
    \subsection{Robust masters}
        \todo{scala standalone vs our pyspark workaround. kill masters in experiments}
    \subsection{Checkpointing}
        \todo{metric for determining how often to checkpoint based on cluster size}
    \subsection{Job arrays}
        \todo{need to kill idle workers. may not want all workers to be running at once.}
    \subsection{Example application}
        \todo{incrementation with varying task durations}
\section{Discussion}\label{sec:discussion}
\section{Conclusion}\label{sec:conclusion}

\end{document}
